import os
import requests
import json
import time
from datetime import datetime
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
GITHUB_USERNAME = os.getenv("GITHUB_USERNAME")
BASE_URL = "https://api.github.com"

class GitHubFetcher:
    def __init__(self, username=None, token=None):
        self.username = username or GITHUB_USERNAME
        self.token = token or GITHUB_TOKEN
        self.headers = {
            "Accept": "application/vnd.github.v3+json"
        }
        if self.token:
            self.headers["Authorization"] = f"token {self.token}"
        else:
            print("WARNING: No GitHub token provided. Rate limits will be low.")

    def _get(self, endpoint, params=None):
        url = f"{BASE_URL}/{endpoint}"
        response = requests.get(url, headers=self.headers, params=params)
        if response.status_code == 200:
            return response.json()
        elif response.status_code == 403:
            print(f"Rate limit exceeded or access forbidden: {response.text}")
            return None
        else:
            print(f"Error fetching {url}: {response.status_code}")
            return None

    def fetch_user_profile(self):
        print(f"Fetching profile for {self.username}...")
        return self._get(f"users/{self.username}")

    def fetch_repositories(self):
        print(f"Fetching repositories for {self.username}...")
        repos = []
        page = 1
        while True:
            data = self._get(f"users/{self.username}/repos", params={"per_page": 100, "page": page})
            if not data:
                break
            repos.extend(data)
            page += 1
        return repos

    def fetch_repo_details(self, repo_name):
        print(f"Fetching details for {repo_name}...")
        languages = self._get(f"repos/{self.username}/{repo_name}/languages")
        readme = self._get(f"repos/{self.username}/{repo_name}/readme")
        
        readme_content = ""
        if readme and "content" in readme:
            import base64
            try:
                readme_content = base64.b64decode(readme["content"]).decode("utf-8")
            except Exception as e:
                print(f"Error decoding README for {repo_name}: {e}")

        commits = self._get(f"repos/{self.username}/{repo_name}/commits", params={"per_page": 10}) # Limit commits for now
        
        return {
            "languages": languages,
            "readme": readme_content,
            "recent_commits": commits
        }

    def fetch_all_data(self):
        profile = self.fetch_user_profile()
        if not profile:
            return None
        
        repos = self.fetch_repositories()
        full_data = {
            "profile": profile,
            "repositories": []
        }

        if repos:
            for repo in repos:
                if repo.get("fork", False):
                    continue # Skip forked repos for now or handle differently
                
                repo_name = repo["name"]
                details = self.fetch_repo_details(repo_name)
                
                repo_data = {
                    "metadata": repo,
                    "details": details
                }
                full_data["repositories"].append(repo_data)
                time.sleep(1) # Be nice to API

        return full_data

    def save_data(self, data, filename="data/raw_data.json"):
        os.makedirs("data", exist_ok=True)
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=4)
        print(f"Data saved to {filename}")

if __name__ == "__main__":
    fetcher = GitHubFetcher()
    data = fetcher.fetch_all_data()
    if data:
        fetcher.save_data(data)
